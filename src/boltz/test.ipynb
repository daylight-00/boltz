{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Checking input data.\n",
      "Running predictions for 1 structure\n",
      "Processing input data.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|          | 0/1 [00:00<?, ?it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Generating MSA for test.fasta with 1 protein entities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "COMPLETE: 100%|██████████| 150/150 [elapsed: 00:02 remaining: 00:00]\n",
      "100%|██████████| 1/1 [00:02<00:00,  2.55s/it]\n",
      "GPU available: True (cuda), used: True\n",
      "TPU available: False, using: 0 TPU cores\n",
      "HPU available: False, using: 0 HPUs\n",
      "/home/hwjang/miniconda3/envs/boltz/lib/python3.12/site-packages/pytorch_lightning/trainer/connectors/logger_connector/logger_connector.py:75: Starting from v1.9.0, `tensorboardX` has been removed as a dependency of the `pytorch_lightning` package, due to potential conflicts with other packages in the ML ecosystem. For this reason, `logger=True` will use `CSVLogger` as the default logger, unless the `tensorboard` or `tensorboardX` packages are found. Please `pip install lightning[extra]` or one of them to enable TensorBoard support by default\n",
      "You are using a CUDA device ('NVIDIA GeForce RTX 4090') that has Tensor Cores. To properly utilize them, you should set `torch.set_float32_matmul_precision('medium' | 'high')` which will trade-off precision for performance. For more details, read https://pytorch.org/docs/stable/generated/torch.set_float32_matmul_precision.html#torch.set_float32_matmul_precision\n",
      "LOCAL_RANK: 0 - CUDA_VISIBLE_DEVICES: [0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Predicting DataLoader 0: 100%|██████████| 1/1 [01:31<00:00,  0.01it/s]Number of failed examples: 0\n",
      "Predicting DataLoader 0: 100%|██████████| 1/1 [01:31<00:00,  0.01it/s]\n"
     ]
    }
   ],
   "source": [
    "from main_test import predict\n",
    "\n",
    "params = {\n",
    "    \"data\": \"test.fasta\",  # Replace with your input data path\n",
    "    \"out_dir\": \"temp\",  # Replace with your desired output directory\n",
    "    \"cache\": \"/home/hwjang/project/IMG/cache\",  # Optional: Replace with your cache directory if different\n",
    "    \"checkpoint\": None,  # Optional: Replace with your checkpoint path if using a custom model\n",
    "    \"devices\": 1,  # Number of devices to use (e.g., GPUs)\n",
    "    \"accelerator\": \"gpu\",  # Accelerator type: 'gpu', 'cpu', 'tpu'\n",
    "    \"recycling_steps\": 3,\n",
    "    \"sampling_steps\": 200,\n",
    "    \"diffusion_samples\": 1,\n",
    "    \"step_scale\": 1.638,\n",
    "    \"write_full_pae\": False,\n",
    "    \"write_full_pde\": False,\n",
    "    \"output_format\": \"mmcif\",  # Options: 'pdb', 'mmcif'\n",
    "    \"num_workers\": 2,\n",
    "    \"override\": True,\n",
    "    \"seed\": None,  # Optional: Set a seed for reproducibility\n",
    "    \"use_msa_server\": True,\n",
    "    \"msa_server_url\": \"https://api.colabfold.com\",\n",
    "    \"msa_pairing_strategy\": \"greedy\",\n",
    "}\n",
    "\n",
    "# Call the predict function with the defined parameters\n",
    "predict(**params)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "boltz",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
